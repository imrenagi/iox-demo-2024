{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain on Vertex AI - Mamang Chatbot Use Case\n",
    "\n",
    "This jupyter notebook will be used to deploy a chatbot built using the Langchain model on Vertex AI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing dependencies\n",
    "\n",
    "!pip install --upgrade --quiet \\\n",
    "    google-cloud-aiplatform \\\n",
    "    langchain \\\n",
    "    langchain-google-vertexai \\\n",
    "    cloudpickle \\\n",
    "    pydantic \\\n",
    "    langchain_google_community \\\n",
    "    google-cloud-discoveryengine \\\n",
    "    google-api-python-client \\\n",
    "    google-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up few variables\n",
    "\n",
    "PROJECT_ID = \"imrenagi-gemini-experiment\"\n",
    "LOCATION = \"us-central1\"  \n",
    "STAGING_BUCKET = \"gs://courses-imrenagicom-agent\"  \n",
    "DATA_STORE_ID = \"course-software-instrumentation_1719363827721\"\n",
    "LOCATION_ID = \"global\"\n",
    "LLM_MODEL = \"gemini-1.5-pro-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries since I'm just an importir\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_google_community import VertexAISearchRetriever\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing vertex AI \n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model safety settings\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}\n",
    "\n",
    "## Model parameters\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"safety_settings\": safety_settings,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Course Content Tool\n",
    "\n",
    "This tool will be used to search for course content based on the user's query and execute query to Vertex AI Search datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_course_content(query: str) -> str:\n",
    "    \"\"\"Explain about software instrumentation course materials.\"\"\"\n",
    "    from langchain_google_community import VertexAISearchRetriever\n",
    "\n",
    "    retriever = VertexAISearchRetriever(\n",
    "        project_id=PROJECT_ID,\n",
    "        data_store_id=DATA_STORE_ID,\n",
    "        location_id=LOCATION_ID,\n",
    "        engine_data_type=0,\n",
    "        max_documents=10,\n",
    "    )\n",
    "\n",
    "    result = str(retriever.invoke(query))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrenagi.com API Client\n",
    "\n",
    "This is the implementation of a simple HTTP client which interacts to my API server. Since the API is protected with Id Token, caller must provide the JWT bearer token on each request. To simplify this, we are using the `google-auth` library to generate the token and to manage token's lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.auth import compute_engine\n",
    "from google.auth.transport.requests import AuthorizedSession, Request\n",
    "import os\n",
    "\n",
    "sa_path = '/home/imrenagi/projects/app/secrets/course-imrenagi.json'\n",
    "\n",
    "class ImreNagiComAPIClient:\n",
    "  def __init__(self, url=\"https://api-dev.imrenagi.com\", service_account_key=None, aud=\"api\"):\n",
    "    self.url = url\n",
    "    credentials = None   \n",
    "    \n",
    "    if service_account_key and os.path.exists(service_account_key):\n",
    "      # Use service account credentials\n",
    "      credentials = service_account.IDTokenCredentials.from_service_account_file(service_account_key, target_audience=aud)\n",
    "    else:\n",
    "      # Use compute engine credentials. This is used when agent is running in reasoning engine.\n",
    "      request = Request()\n",
    "      credentials = compute_engine.IDTokenCredentials(\n",
    "          request=request, target_audience=aud, use_metadata_identity_endpoint=True\n",
    "      )\n",
    "      credentials.refresh(request)\n",
    "    self.authed_session = AuthorizedSession(credentials)\n",
    "    \n",
    "  def list_courses(self):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses\")\n",
    "    return response.json()\n",
    "  \n",
    "  def get_course(self, course):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses/{course}\")\n",
    "    return response.json()\n",
    "  \n",
    "  def create_order(self, course, package, user_name, user_email):\n",
    "    response = self.authed_session.post(f\"{self.url}/api/v1/courses/orders\", json={\n",
    "      \"course\": course, \n",
    "      \"package\": package, \n",
    "      \"customer\": {\n",
    "        \"name\": user_name,\n",
    "        \"email\": user_email\n",
    "      },\n",
    "      \"payment\": {\n",
    "        \"method\": \"gopay\"\n",
    "      }})\n",
    "    return response.json()\n",
    "  \n",
    "  def get_order(self, order_id):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses/orders/{order_id}\")\n",
    "    return response.json()\n",
    "  \n",
    "  def get_invoice(self, invoice_number):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/invoices/{invoice_number}\")\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrenagi.com API Tools\n",
    "\n",
    "These tools below are just a langchain tools wrapper that interact with the API server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def list_courses() -> List[str]:\n",
    "  \"\"\"List all available courses sold on the platform.\"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  return client.list_courses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCourseInput(BaseModel):\n",
    "    course: str = Field(description=\"name of the course. this is the unique identifier of the course. it typically contains the course title with dashes, all in lowercase.\")\n",
    "\n",
    "@tool(\"get-course-tool\", args_schema=GetCourseInput)\n",
    "def get_course(course: str) -> str:\n",
    "  \"\"\"Get course details by course name. course name is the unique identifier of the course. it typically contains the course title with dashes.\n",
    "  This function can be used to get course details such as course packages price, etc.\"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  return client.get_course(course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateOrderInput(BaseModel):\n",
    "    course: str = Field(description=\"name of the course. this is the unique identifier of the course. it typically contains the course title with dashes, all in lowercase.\")\n",
    "    package: str = Field(description=\"name of the course package. this is the unique identifier of the course package. it typically contains the package title with dashes, all in lowercase.\")\n",
    "    user_name: str = Field(description=\"name of the user who is purchasing the course package.\")\n",
    "    user_email: str = Field(description=\"email of the user who is purchasing the course package.\")\n",
    "\n",
    "@tool(\"create-order-tool\", args_schema=CreateOrderInput)\n",
    "def create_order(course: str, package: str, user_name: str, user_email: str) -> str:\n",
    "  \"\"\"Create order for a course package. This function can be used to create an order for a course package. When this function returns successfully, it will return payment url to user to make payment. \"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  \n",
    "  order = client.create_order(course, package, user_name, user_email)\n",
    "  print(order)\n",
    "  time.sleep(5)\n",
    "  \n",
    "  payment_url = None\n",
    "  order_number = order['number']\n",
    "  for i in range(3):\n",
    "    try:\n",
    "      order = client.get_order(order['number'])\n",
    "      invoice_number = order['payment']['invoiceNumber']\n",
    "      \n",
    "      invoice = client.get_invoice(invoice_number)\n",
    "      payment_url = invoice['payment']['redirectUrl']\n",
    "      break\n",
    "    except Exception as e:\n",
    "      print(f\"Error getting order: {e}\")\n",
    "      time.sleep(5)\n",
    "  \n",
    "  return f\"Order number {order_number} created successfully. Payment URL: {payment_url}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetOrderInput(BaseModel):\n",
    "    order_number: str = Field(description=\"order number identifier. this is a unique identifier in uuid format.\")\n",
    "\n",
    "@tool(\"get-order-tool\", args_schema=GetOrderInput)\n",
    "def get_order(order_number: str) -> str:\n",
    "  \"\"\"Get order by using order number. This function can be used to get order details such as payment status to check whether the order has been paid or not. If user already paid the course, tell them to check for their enrollment email\"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  return client.get_order(order_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': '09ea5dc0-461d-4454-9384-a6b69d84df75', 'course': 'software-instrumentation', 'package': 'basic', 'price': 100000, 'currency': 'IDR', 'status': 'CREATED', 'createdAt': '2024-07-13T06:33:58.162808710Z', 'paidAt': None, 'customer': {'name': 'Imre Nagi', 'email': 'imre.nagi2812@gmail.com', 'phoneNumber': '', 'shippingAddress': None, 'billingAddress': None}, 'payment': {'invoiceNumber': '', 'method': 'gopay'}, 'expiredAt': '2024-07-13T06:43:58.162809039Z', 'failedAt': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Order number 09ea5dc0-461d-4454-9384-a6b69d84df75 created successfully. Payment URL: https://app.sandbox.midtrans.com/snap/v4/redirection/f2739d7b-799a-4a66-9ad9-a7d393109635'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_courses.invoke({\"input\":\"\"})\n",
    "# get_course.invoke({\"course\":\"software-instrumentation\"})\n",
    "create_order.invoke({\"course\":\"software-instrumentation\", \"package\":\"basic\", \"user_name\":\"Imre Nagi\", \"user_email\":\"imre.nagi2812@gmail.com\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all tools\n",
    "\n",
    "tools = [search_course_content, list_courses, get_course, create_order, get_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "This is the prompt that will be used to interact with model. I enabled chat history and agent scratchpad so that we can pass the message history and the result from Gemini function call to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    \"chat_history\": lambda x: x[\"history\"],\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": (\n",
    "        lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    "    ),\n",
    "} | ChatPromptTemplate(\n",
    "  messages = [\n",
    "    SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "      You are a bot assistant that sells online course about software instrumentation. You only use information provided from datastore or tools. You can provide the information that is relevant to the user's question or the summary of the content. If they ask about the content, you can give them more detail about the content. If the user seems interested, you may suggest the user to enroll in the course. \n",
    "      \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    HumanMessagePromptTemplate.from_template(\"Use tools to answer this questions: {input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Message History\n",
    "\n",
    "This will be used to store the chat history for each user sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent\n",
    "\n",
    "While langchain is actually has API to create an agent, in this case we are using `reasoning_engines.LangchainAgent()` to create the agent. Once it is created, you can still use the exact same API to invoke the model as you would when you are using standard langchain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM_MODEL\n",
    "\n",
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,    \n",
    "    chat_history=get_session_history,\n",
    "    agent_executor_kwargs={\n",
    "      \"return_intermediate_steps\": True,\n",
    "    },\n",
    "    model_kwargs=model_kwargs,\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 66afc2c6-7802-4030-b99f-6e7c8d324b9b not found for run 98af0f5a-61db-4db0-a14a-6db3161d2e62. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your order is completed. Please check your email imre.nagi2812@gmail.com for the enrollment information. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  # input=\"I want to purchase software instrumentation course. I want to get the basic package. My name is imre and email is imre.nagi2812@gmail.com\",\n",
    "  input=\"I have made the payment. Can you please check my order status? What's next?\",\n",
    "  config={\"configurable\": {\"session_id\": \"demo1234\"}},\n",
    "  )\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the Agent on Vertex AI\n",
    "\n",
    "Deploying is as simple as calling `create()` method. We will provide the agent here and some dependencies required to run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket courses-imrenagicom-agent\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/896489987664/locations/us-central1/reasoningEngines/4254318351121121280/operations/1098809898839310336\n",
      "ReasoningEngine created. Resource name: projects/896489987664/locations/us-central1/reasoningEngines/4254318351121121280\n",
      "To use this ReasoningEngine in another session:\n",
      "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/896489987664/locations/us-central1/reasoningEngines/4254318351121121280')\n"
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform==1.51.0\",\n",
    "        \"langchain==0.1.20\",\n",
    "        \"langchain-google-vertexai==1.0.3\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic==2.7.1\",        \n",
    "        \"requests==2.32.3\",\n",
    "        \"langchain_google_community\",\n",
    "        \"google-cloud-discoveryengine\",\n",
    "        \"google-auth\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the final log challenge, you'll work on a demo application with some intentionally injected bugs. Your mission is to pinpoint and resolve these bugs **solely through instrumenting the app with logs, analyzing them, and interpreting the resulting metrics.**  The challenge revolves around eliminating 5xx errors and gRPC `Unknown` status codes reported during load testing. \n",
       "\n",
       "Let me know if you'd like a more detailed explanation of the challenge or want to explore specific aspects of it. And, if you're up for the challenge, our course can equip you with the skills to tackle this and many other real-world instrumentation scenarios! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the remote agent\n",
    "response = remote_agent.query(\n",
    "  input=\"Can you share about the problems discussed on final log challenge?\",\n",
    "  config={\"configurable\": {\"session_id\": \"test1235\"}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "Don't forget to clean up the resources after you are done with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x7f4f2f34fa90> \n",
       " resource name: projects/896489987664/locations/us-central1/reasoningEngines/4254318351121121280,\n",
       " <vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x7f4f2f34ece0> \n",
       " resource name: projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_engines.ReasoningEngine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting ReasoningEngine : projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968\n",
      "ReasoningEngine deleted. . Resource name: projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968\n",
      "Deleting ReasoningEngine resource: projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968\n",
      "Delete ReasoningEngine backing LRO: projects/896489987664/locations/us-central1/operations/2036790074355482624\n",
      "ReasoningEngine resource projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968 deleted.\n"
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine('projects/896489987664/locations/us-central1/reasoningEngines/2776011773436755968')\n",
    "\n",
    "remote_agent.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
