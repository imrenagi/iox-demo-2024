{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain on Vertex AI - Mamang Chatbot Use Case\n",
    "\n",
    "This jupyter notebook will be used to deploy a chatbot built using the Langchain model on Vertex AI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing dependencies\n",
    "\n",
    "!pip install --upgrade --quiet \\\n",
    "    google-cloud-aiplatform \\\n",
    "    langchain \\\n",
    "    langchain-google-vertexai \\\n",
    "    cloudpickle \\\n",
    "    pydantic \\\n",
    "    langchain_google_community \\\n",
    "    google-cloud-discoveryengine \\\n",
    "    google-api-python-client \\\n",
    "    google-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up few variables\n",
    "\n",
    "PROJECT_ID = \"imrenagi-gemini-experiment\"\n",
    "LOCATION = \"us-central1\"  \n",
    "STAGING_BUCKET = \"gs://courses-imrenagicom-agent\"  \n",
    "DATA_STORE_ID = \"course-software-instrumentation_1719363827721\"\n",
    "LOCATION_ID = \"global\"\n",
    "LLM_MODEL = \"gemini-1.5-pro-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries since I'm just an importir\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_google_community import VertexAISearchRetriever\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview import reasoning_engines\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing vertex AI \n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model safety settings\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}\n",
    "\n",
    "## Model parameters\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"safety_settings\": safety_settings,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Course Content Tool\n",
    "\n",
    "This tool will be used to search for course content based on the user's query and execute query to Vertex AI Search datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_course_content(query: str) -> str:\n",
    "    \"\"\"Explain about software instrumentation course materials.\"\"\"\n",
    "    from langchain_google_community import VertexAISearchRetriever\n",
    "\n",
    "    retriever = VertexAISearchRetriever(\n",
    "        project_id=PROJECT_ID,\n",
    "        data_store_id=DATA_STORE_ID,\n",
    "        location_id=LOCATION_ID,\n",
    "        engine_data_type=0,\n",
    "        max_documents=10,\n",
    "    )\n",
    "\n",
    "    result = str(retriever.invoke(query))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrenagi.com API Client\n",
    "\n",
    "This is the implementation of a simple HTTP client which interacts to my API server. Since the API is protected with Id Token, caller must provide the JWT bearer token on each request. To simplify this, we are using the `google-auth` library to generate the token and to manage token's lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.auth import compute_engine\n",
    "from google.auth.transport.requests import AuthorizedSession, Request\n",
    "import os\n",
    "\n",
    "sa_path = '/home/imrenagi/projects/app/secrets/course-imrenagi.json'\n",
    "\n",
    "class ImreNagiComAPIClient:\n",
    "  def __init__(self, url=\"https://api-dev.imrenagi.com\", service_account_key=None, aud=\"api\"):\n",
    "    self.url = url\n",
    "    credentials = None   \n",
    "    \n",
    "    if service_account_key and os.path.exists(service_account_key):\n",
    "      # Use service account credentials\n",
    "      credentials = service_account.IDTokenCredentials.from_service_account_file(service_account_key, target_audience=aud)\n",
    "    else:\n",
    "      # Use compute engine credentials. This is used when agent is running in reasoning engine.\n",
    "      request = Request()\n",
    "      credentials = compute_engine.IDTokenCredentials(\n",
    "          request=request, target_audience=aud, use_metadata_identity_endpoint=True\n",
    "      )\n",
    "      credentials.refresh(request)\n",
    "    self.authed_session = AuthorizedSession(credentials)\n",
    "    \n",
    "  def list_courses(self):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses\")\n",
    "    return response.json()\n",
    "  \n",
    "  def get_course(self, course):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses/{course}\")\n",
    "    return response.json()\n",
    "  \n",
    "  def create_order(self, course, package, user_name, user_email):\n",
    "    response = self.authed_session.post(f\"{self.url}/api/v1/courses/orders\", json={\n",
    "      \"course\": course, \n",
    "      \"package\": package, \n",
    "      \"customer\": {\n",
    "        \"name\": user_name,\n",
    "        \"email\": user_email\n",
    "      },\n",
    "      \"payment\": {\n",
    "        \"method\": \"gopay\"\n",
    "      }})\n",
    "    return response.json()\n",
    "  \n",
    "  def get_order(self, order_id):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/courses/orders/{order_id}\")\n",
    "    return response.json()\n",
    "  \n",
    "  def get_invoice(self, invoice_number):\n",
    "    response = self.authed_session.get(f\"{self.url}/api/v1/invoices/{invoice_number}\")\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrenagi.com API Tools\n",
    "\n",
    "These tools below are just a langchain tools wrapper that interact with the API server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@tool\n",
    "def list_courses() -> List[str]:\n",
    "  \"\"\"List all available courses sold on the platform.\"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  return client.list_courses()\n",
    "\n",
    "@tool\n",
    "def get_course(course: str) -> str:\n",
    "  \"\"\"Get course details by course name. course name is the unique identifier of the course. it typically contains the course title with dashes.\n",
    "  This function can be used to get course details such as course packages price, etc.\"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  return client.get_course(course)\n",
    "\n",
    "@tool\n",
    "def create_order(course: str, package: str, user_name: str, user_email: str) -> str:\n",
    "  \"\"\"Create order for a course package. This function can be used to create an order for a course package. When this function returns successfully, it will return payment url to user to make payment. \"\"\"\n",
    "  client = ImreNagiComAPIClient(\n",
    "    service_account_key=sa_path\n",
    "  )\n",
    "  \n",
    "  order = client.create_order(course, package, user_name, user_email)\n",
    "  print(order)\n",
    "  \n",
    "  time.sleep(5)  \n",
    "  \n",
    "  order = client.get_order(order['number'])\n",
    "  invoice_number = order['payment']['invoiceNumber']\n",
    "  \n",
    "  invoice = client.get_invoice(invoice_number)\n",
    "  payment_url = invoice['payment']['redirectUrl']\n",
    "  \n",
    "  return f\"Order created successfully. Payment URL: {payment_url}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_courses.invoke({\"input\":\"\"})\n",
    "# get_course.invoke({\"course\":\"software-instrumentation\"})\n",
    "# create_order.invoke({\"course\":\"software-instrumentation\", \"package\":\"basic\", \"user_name\":\"Imre Nagi\", \"user_email\":\"imre.nagi2812@gmail.com\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all tools\n",
    "\n",
    "tools = [search_course_content, list_courses, get_course, create_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "This is the prompt that will be used to interact with model. I enabled chat history and agent scratchpad so that we can pass the message history and the result from Gemini function call to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    \"chat_history\": lambda x: x[\"history\"],\n",
    "    \"input\": lambda x: x[\"input\"],\n",
    "    \"agent_scratchpad\": (\n",
    "        lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
    "    ),\n",
    "} | ChatPromptTemplate(\n",
    "  messages = [\n",
    "    SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "      You are a bot assistant that sells online course about software instrumentation. You only use information provided from datastore or tools. You can provide the information that is relevant to the user's question or the summary of the content. If the user asks for more information, you may suggest the user to enroll in the course. \n",
    "      \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    HumanMessagePromptTemplate.from_template(\"Use tools to answer this questions: {input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Message History\n",
    "\n",
    "This will be used to store the chat history for each user sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent\n",
    "\n",
    "While langchain is actually has API to create an agent, in this case we are using `reasoning_engines.LangchainAgent()` to create the agent. Once it is created, you can still use the exact same API to invoke the model as you would when you are using standard langchain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM_MODEL\n",
    "\n",
    "agent = reasoning_engines.LangchainAgent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    prompt=prompt,    \n",
    "    chat_history=get_session_history,\n",
    "    agent_executor_kwargs={\n",
    "      \"return_intermediate_steps\": True,\n",
    "    },\n",
    "    model_kwargs=model_kwargs,\n",
    "    enable_tracing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opentelemetry-exporter-gcp-trace is not installed. Please call 'pip install google-cloud-aiplatform[langchain]'.\n",
      "enable_tracing=True but proceeding with tracing disabled because not all packages for tracing have been installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run fa6a6fd6-19d5-4d55-8a7d-97bda57530d8 not found for run 86fbc829-6ea8-4c50-8185-0c3d5f3af0d1. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This course is designed for beginner and intermediate software engineers who are interested in learning about software instrumentation and monitoring. \n",
       "\n",
       "Here are a few things you will learn:\n",
       "- Fundamental ideas behind software instrumentation and monitoring\n",
       "- Setting up basic tech stacks for tracing, logging, and monitoring in a cloud native environment\n",
       "- Different instrumentation techniques to understand the performance and how your application behaves\n",
       "- Performing instrumentation for applications consisting of multiple dependencies \n",
       "- Using instrumentation to diagnose performance issues, reliability issues, and business-relevant metrics.\n",
       "\n",
       "Would you like to learn more about the course?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "  input=\"Can you share what the software instrumentation course content offers?\",\n",
    "  config={\"configurable\": {\"session_id\": \"demo1234\"}},\n",
    "  )\n",
    "\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the Agent on Vertex AI\n",
    "\n",
    "Deploying is as simple as calling `create()` method. We will provide the agent here and some dependencies required to run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket courses-imrenagicom-agent\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/reasoning_engine.pkl\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://courses-imrenagicom-agent/reasoning_engine/dependencies.tar.gz\n",
      "Creating ReasoningEngine\n",
      "Create ReasoningEngine backing LRO: projects/896489987664/locations/us-central1/reasoningEngines/3647247195100413952/operations/8301296056516214784\n",
      "ReasoningEngine created. Resource name: projects/896489987664/locations/us-central1/reasoningEngines/3647247195100413952\n",
      "To use this ReasoningEngine in another session:\n",
      "reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/896489987664/locations/us-central1/reasoningEngines/3647247195100413952')\n"
     ]
    }
   ],
   "source": [
    "remote_agent = reasoning_engines.ReasoningEngine.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform==1.51.0\",\n",
    "        \"langchain==0.1.20\",\n",
    "        \"langchain-google-vertexai==1.0.3\",\n",
    "        \"cloudpickle==3.0.0\",\n",
    "        \"pydantic==2.7.1\",        \n",
    "        \"requests==2.32.3\",\n",
    "        \"langchain_google_community\",\n",
    "        \"google-cloud-discoveryengine\",\n",
    "        \"google-auth\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the remote agent\n",
    "response = remote_agent.query(\n",
    "  input=\"Can you please share what being taught on software instrumentation course?\",\n",
    "  config={\"configurable\": {\"session_id\": \"test1235\"}},\n",
    ")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "Don't forget to clean up the resources after you are done with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_agent = reasoning_engines.ReasoningEngine('projects/896489987664/locations/us-central1/reasoningEngines/3647247195100413952')\n",
    "\n",
    "# remote_agent.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
